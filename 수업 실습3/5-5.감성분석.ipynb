{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 감성분석"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텍스트에 나타난 주관적 요소를 분석하여 긍정,부정의 요소 및 그 정도를 판별하여 정량화하는 기법\n",
    "- 긍정과 부정을 판별할 뿐 아니라 긍정,부정의 대상이 되는 단어 또는 개체를 추출하고 감성을 표현하는 이의 의도나 입장을 분석하는 것도 포함하는 개념"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.단어사전기반 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성사전을 이용하여 각 단어의 감정 분류와 그 정도를 알 수 있어야 함\n",
    "# 텍스트와 감성지수가 사전에 정의되어 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from afinn import Afinn\n",
    "\n",
    "#감성분석 객체\n",
    "afinn = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob.glob 특정한 패턴의 파일만 선택하는 함수\n",
    "pos_review=(glob.glob(\"c:/vscode/data/imdb/train/pos/*.txt\"))[20]\n",
    "f = open(pos_review, 'r')\n",
    "lines1 = f.readlines()[0]\n",
    "f.close()\n",
    "\n",
    "#텍스트 전처리 후 감성점수 산출\n",
    "afinn.score(lines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/vscode/data/imdb/train/pos\\\\0_9.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10000_8.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10001_10.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10002_7.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10003_8.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10004_8.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10005_7.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10006_7.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10007_7.txt',\n",
       " 'c:/vscode/data/imdb/train/pos\\\\10008_7.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/vscode/data/imdb/train/pos/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "2.0\n",
      "19.0\n",
      "3.0\n",
      "14.0\n",
      "8.0\n",
      "22.0\n",
      "28.0\n",
      "13.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 긍정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() #감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정리뷰데이터 20번째 내용\n",
    "neg_review=(glob.glob(\"c:/vscode/data/imdb/train/neg/*.txt\"))[20]\n",
    "f = open(neg_review, 'r')\n",
    "lines2 = f.readlines()[0]\n",
    "f.close()\n",
    "\n",
    "afinn.score(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/vscode/data/imdb/train/neg\\\\0_3.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10000_4.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10001_4.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10002_1.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10003_1.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10004_3.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10005_3.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10006_4.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10007_1.txt',\n",
       " 'c:/vscode/data/imdb/train/neg\\\\10008_2.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/vscode/data/imdb/train/neg/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "-4.0\n",
      "9.0\n",
      "5.0\n",
      "-7.0\n",
      "1.0\n",
      "13.0\n",
      "4.0\n",
      "7.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 부정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() #감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.기계학습으로 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "#긍정 텍스트 로딩\n",
    "pos_review=(glob.glob(\"c:/vscode/data/imdb/train/pos/*.txt\")[:100])\n",
    "lines_pos=[]\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정 텍스트 로딩\n",
    "neg_review=(glob.glob(\"c:/vscode/data/imdb/train/neg/*.txt\")[:100])\n",
    "lines_neg=[]\n",
    "for i in neg_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_neg.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정,부정 리뷰를 합침\n",
    "total_text = lines_pos + lines_neg\n",
    "len(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#긍정,부정 클래스 라벨링\n",
    "x = np.array([\"pos\", \"neg\"])\n",
    "class_Index = np.repeat(x, [len(lines_pos), len(lines_neg)], axis=0)\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#단어들에 Tfidf 가중치를 부여한 후 문서-단어 매트릭스로 바꿈\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words=stop_words).fit(total_text)\n",
    "X_train_vectorized = vect.transform(total_text)\n",
    "X_train_vectorized.index = class_Index\n",
    "\n",
    "#데이터프레임으로 변환\n",
    "df=pd.DataFrame(X_train_vectorized.toarray(),\n",
    "                columns=vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 리뷰들을 하나씩 불러와서 실험\n",
    "def pos_review(model):\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "    tests1=[]\n",
    "    for idx in range(0,num):\n",
    "        pos_review_test=(glob.glob(\"c:/vscode/data/imdb/test/pos/*.txt\"))[idx]\n",
    "        f = open(pos_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests1.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests1:\n",
    "        pred = model.predict(vect.transform(test))\n",
    "        result=pred[0]\n",
    "        if result==\"pos\":\n",
    "            count+=1\n",
    "        count_all += 1\n",
    "    rate= count*100/count_all\n",
    "    print(f\"분류정확도:{rate:.1f}%\")\n",
    "\n",
    "#부정 리뷰들을 하나씩 불러와서 실험\n",
    "def neg_review(model):\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "    tests2=[]\n",
    "    for idx in range(0,num):\n",
    "        neg_review_test=(glob.glob(\"c:/vscode/data/imdb/test/neg/*.txt\"))[idx]\n",
    "        f = open(neg_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests2.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests2:\n",
    "        preds = model.predict(vect.transform(test))\n",
    "        result=preds[0]\n",
    "        if result==\"neg\":\n",
    "            count+=1\n",
    "        count_all+=1\n",
    "    rate= count*100/count_all\n",
    "    print(\"예측정확도:{0:.1f}%\".format(rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:66.0%\n",
      "예측정확도:82.0%\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모형\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(random_state=10)\n",
    "logit.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(logit)\n",
    "neg_review(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:54.0%\n",
      "예측정확도:54.0%\n"
     ]
    }
   ],
   "source": [
    "#의사결정나무 모형\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(tree)\n",
    "neg_review(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:46.0%\n",
      "예측정확도:70.0%\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#10개의 트리로 구성된 랜덤 포레스트\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=10)\n",
    "forest.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(forest)\n",
    "neg_review(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:34.0%\n",
      "예측정확도:85.0%\n"
     ]
    }
   ],
   "source": [
    "# knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(knn)\n",
    "neg_review(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:63.0%\n",
      "예측정확도:76.0%\n"
     ]
    }
   ],
   "source": [
    "# mlp 인공신경망\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=10)\n",
    "mlp.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(mlp)\n",
    "neg_review(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:63.0%\n",
      "예측정확도:86.0%\n"
     ]
    }
   ],
   "source": [
    "#SVM 모형\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(random_state=10)\n",
    "svm.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(svm)\n",
    "neg_review(svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> textblob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한글도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    ('What an awesome view', 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "\n",
    "test = [\n",
    "    ('The beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    ('I am not feeling dandy today.', 'neg'),\n",
    "    ('I feel amazing!', 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "cl = NaiveBayesClassifier(train)\n",
    "print(cl.classify('Their burgers are amazing'))\n",
    "print(cl.classify(\"I don't like their pizza.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#여러 문장을 종합하여 부정으로 분류\n",
    "blob = TextBlob(\"The beer was amazing. But the hangover was horrible. My boss was not happy.\", \n",
    "                classifier=cl)\n",
    "blob.classify() # \"neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer was amazing. ==> pos\n",
      "But the hangover was horrible. ==> neg\n",
      "My boss was not happy. ==> neg\n",
      "\n",
      "The beer was good. ==> pos\n",
      "I do not enjoy my job ==> neg\n",
      "I am not feeling dandy today. ==> neg\n",
      "I feel amazing! ==> pos\n",
      "Gary is a friend of mine. ==> neg\n",
      "I can't believe I'm doing this. ==> neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#개별 문장으로 분류\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence, '==>', sentence.classify())\n",
    "# \"pos\", \"neg\", \"neg\"\n",
    "print('')\n",
    "\n",
    "for row in test:\n",
    "    print(row[0],'==>', cl.classify(row[0]))\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
