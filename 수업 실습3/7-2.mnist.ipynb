{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train= X_train.reshape(-1,784)\n",
    "X_test= X_test.reshape(-1,784)\n",
    "\n",
    "X_train=X_train/255.\n",
    "X_test=X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "plt.imshow(X_train[0].reshape(28,28),cmap=cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 학습용 데이터 텐서 변환\n",
    "# from_numpy() 넘파이배열을 텐서로 변환\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train.astype('int32')).long()\n",
    "\n",
    "# 검증용 데이터 텐서 변환\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test.astype('int32')).long()\n",
    "\n",
    "# 변환된 텐서의 샘플수 확인\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=X_train.cuda()\n",
    "# y_train=y_train.cuda()\n",
    "# X_test=X_test.cuda()\n",
    "# y_test=y_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# 독립변수와 종속변수 텐서를 합침\n",
    "train = TensorDataset(X_train, y_train)\n",
    "# 미니배치 분할\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 128)\n",
    "        self.fc6 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 손실함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화함수\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for X_train, y_train in train_loader:\n",
    "        # 계산 그래프 구성\n",
    "        X_train, y_train = Variable(X_train), Variable(y_train)\n",
    "        X_train=X_train\n",
    "        y_train=y_train\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(X_train)\n",
    "        # 오차계산\n",
    "        loss = criterion(output, y_train)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "    # 10회 반복마다 누적오차 출력\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계산 그래프 구성\n",
    "X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "result = torch.max(model(X_test).data, 1)[1]\n",
    "y_test=y_test\n",
    "result=result\n",
    "print(result[:5]) # 출력값\n",
    "print(y_test.data.numpy()[:5]) #실제값\n",
    "\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size=100\n",
    "# batch_size, channels, height, width\n",
    "summary(model, input_size=(batch_size, 784))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플수, 채널(흑백1/컬러3), 가로, 세로\n",
    "X_train= X_train.reshape(-1,1,28,28)\n",
    "X_test= X_test.reshape(-1,1,28,28)\n",
    "X_train=X_train/255.\n",
    "X_test=X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 넘파이배열을 텐서로 이동\n",
    "X_train=torch.from_numpy(X_train).float()\n",
    "y_train=torch.from_numpy(y_train.astype('int32')).long()\n",
    "X_test=torch.from_numpy(X_test).float()\n",
    "y_test=torch.from_numpy(y_test.astype('int32')).long()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서를 gpu로 옮기고\n",
    "X_train=X_train.cuda()\n",
    "y_train=y_train.cuda()\n",
    "X_test=X_test.cuda()\n",
    "y_test=y_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# 독립변수와 종속변수 텐서를 합침\n",
    "train = TensorDataset(X_train, y_train)\n",
    "print(train[0])\n",
    "# 미니배치 분할\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# 신경망 구성\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5 ) # 입력 채널 수(흑백1,컬러3), 출력 채널 수, 필터 크기\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # 풀링 영역 크기\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "# 인스턴스 생성\n",
    "model = Net()#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = Variable(X_train), Variable(y_train) #계산 그래프 구성\n",
    "        #텐서를 gpu로 이동시킴\n",
    "        #X_train=X_train.cuda()\n",
    "        #y_train=y_train.cuda()\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(X_train)\n",
    "        # 오차계산\n",
    "        loss = criterion(output, y_train)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "# 50회 반복마다 누적 오차 출력\n",
    "if (epoch+1) % 50 == 0:\n",
    "    print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "# [0] values, [1] indices\n",
    "# 모형이 분류한 값들(10개) 중 가장 큰 값과 인덱스\n",
    "# 출력이 0 또는 1이 되게 함\n",
    "result = torch.max(model(X_test).data, 1)[1]\n",
    "#print(result)\n",
    "# 모형의 정확도 측정\n",
    "# gpu에 저장된 텐서를 cpu로 이동시킴\n",
    "#y_test=y_test.cpu()\n",
    "#result=result.cpu()\n",
    "accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "batch_size=100\n",
    "# batch_size, channels, height, width\n",
    "summary(model, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> fashion mnist data (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Default CUDA device\n",
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "#이미지 압축파일을 오픈\n",
    "with gzip.open('c:/vscode/data/fashion-mnist/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    # frombuffer(바이트배열, 자료형, 시작점)\n",
    "    mnist_data=np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    # 차원 변경\n",
    "    mnist_data = mnist_data.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mnist_data = mnist_data / 255\n",
    "pd.DataFrame(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지의 라벨\n",
    "with gzip.open('c:/vscode/data/fashion-mnist/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    mnist_label=np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "mnist_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(20,3))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1) \n",
    "    plt.imshow(mnist_data[i].reshape(28,28),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(mnist_data,mnist_label,test_size=0.2,random_state=10)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터 텐서 변환\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "# 검증용 데이터 텐서 변환\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "# 변환된 텐서의 샘플수 확인\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서를 gpu로 옮기고\n",
    "X_train=X_train.cuda()\n",
    "y_train=y_train.cuda()\n",
    "X_test=X_test.cuda()\n",
    "y_test=y_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# 독립변수와 종속변수 텐서를 합침\n",
    "train = TensorDataset(X_train, y_train)\n",
    "# 텐서의 첫 번째 데이터를 확인\n",
    "print(train[0])\n",
    "# 미니배치 분할\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv Layer\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 입력 채널 수, 출력 채널 수,필터 크기\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # 풀링 영역 크기\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "model = Net()#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = Variable(X_train), Variable(y_train) #계산 그래프 구성\n",
    "        #텐서를 gpu로 이동시킴\n",
    "        # X_train=X_train.cuda()\n",
    "        # y_train=y_train.cuda()\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(X_train)\n",
    "        # 오차계산\n",
    "        loss = criterion(output, y_train)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "    # 50회 반복마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계산 그래프 구성\n",
    "X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "# 출력이 0 또는 1이 되게 함\n",
    "result = torch.max(model(X_test).data, 1)[1]\n",
    "# 모형의 정확도 측정\n",
    "# gpu에 저장된 텐서를 cpu로 이동시킴\n",
    "y_test=y_test.cpu()\n",
    "result=result.cpu()\n",
    "accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skorch : pytorch를 쉽게 구현할 수 있는 라이브러리\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.reshape(-1,784)\n",
    "X_test= X_test.reshape(-1,784)\n",
    "X_train=X_train/255.\n",
    "X_test=X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X_train=torch.from_numpy(X_train).float()\n",
    "y_train=torch.from_numpy(y_train.astype('int32')).long()\n",
    "X_test=torch.from_numpy(X_test).float()\n",
    "y_test=torch.from_numpy(y_test.astype('int32')).long()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# X_train=X_train.cuda()\n",
    "# y_train=y_train.cuda()\n",
    "# X_test=X_test.cuda()\n",
    "# y_test=y_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# 신경망 구성\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=-1)\n",
    "model=Net()#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "net = NeuralNetClassifier(Net,max_epochs=20,lr=0.1)\n",
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 모형의 정확도 계산\n",
    "pred = net.predict(X_test)\n",
    "y_test = y_test.cpu().numpy()\n",
    "accuracy = np.mean(pred == y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(100,784))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
